# Social Robot Design Portfolio

## Table of Contents
- [About Me](#about-me)
- Week 1 Design Tools
  - [Group Work](#group-work)
    - [Case Description](#case-description)
    - [Requirements](#requirements)
    - [Selection of Useful Design Tools](#selection-of-useful-design-tools)
    - [Slide](#slide)
  - [Reflections](#reflections)
    - [How is Design Research linked to HRI](#how-is-design-research-linked-to-hri)
    - [Digital (AI) vs Embodiment](#digital-ai-vs-embodiment)
    - [Why is HER not a compelling argument](#why-is-her-not-a-compelling-argument)
    - [The Robot Revolution: When?](#the-robot-revolution-when)
    - [Reflection: The Dinosaur Hotel](#reflection-the-dinosaur-hotel)
    - [Reflection: Nabaztag](#reflection-nabaztag)
    - [Reflection: CuddleBits](#reflection-cuddlebits)
    - [Reflection: Be-Right-Back](#reflection-be-right-back)
- Week 2 Storytelling
  - [Group Work](#group-work)
  - [Reflections](#reflections)
    - [Robot and AI Story Categories](#robot-and-ai-story-categories)
    - [Science Fiction Prototyping vs Scenario-Based Design](#science-fiction-prototyping-vs-scenario-based-design)
    - [Reflection: 21st Century Robot](#reflection-21st-century-robot)
    - [Reflection: Product Stories vs Reality](#reflection-product-stories-vs-reality)
    - [Why Storytelling Matters in Social Robot Design](#why-storytelling-matters-in-social-robot-design)
    - [Reflection: Healthcare vs Social Robot Stories](#reflection-healthcare-vs-social-robot-stories)
      
- Week 3 Expression
  - [Group Work: Experiment and Design Tool](#group-work-experiment-and-design-tool)

  - [Reflections](#reflections)
    - [Lessons from Ju and Hoffmann](#lessons-from-ju-and-hoffmann)
    - [Laban Framework and Alternatives](#laban-framework-and-alternatives)
    - [Designing Robot Movement](#designing-robot-movement)
    - [Sound Design, Haptics and Morphology](#sound-design-haptics-and-morphology)
    - [Anti-Social Robot Design](#anti-social-robot-design)

- Week 4 Embodiment
  - [Group Work](#group-work)
  - [Reflections](#reflections)
    - [Embodied vs Virtual Interaction](#embodied-vs-virtual-interaction)
    - [Designing Robot Interaction](#designing-robot-interaction)
    - [Anthropomorphism vs Function](#anthropomorphism-vs-function)
    - [Function Defines Form](#function-defines-form)
   
- Week 5 Tools for ROSE
  - [Expression](#expression)
 
- Week 6 Behavior
  - [Group Work](#group-work)
    - [Tool: Robot Enactment Game with ChatGPT for Behavior Prototyping](#tool-robot-enactment-game-with-chatgpt-for-behavior-prototyping)
    - [How the Tool Works](#how-the-tool-works)
    - [Challenges with the Tool](#challenges-with-the-tool)
    - [Key Insights and Design Challenges](#key-insights-and-design-challenges)
    - [Lessons Learned from Challenges](#lessons-learned-from-challenges)
---

## About Me

| Member     | Brief Introduction                                                                                                  | Personal Page |
|------------|---------------------------------------------------------------------------------------------------------------------|---------------|
| Abishek Samraj Johnson Sembudurai  | MSc student in Robotics, specilisation in Mechatronics and Physical AI, exploring robot control, perception, and HRI design.                                       | [Download My CV](CV.pdf) |

---
## Week 1 Design Tools

## Group Work

### Case Description
After poperly analising the features of ROSE robot (a social robot designed to support healthcare settings), we have categorised them as [View Features Image](Features.jpg) Then our group explored three application ideas for ROSE [View Application Image](Applications.jpg), particularly for elderly care and hospitals. The goal was to create meaningful value through companionship, cognitive stimulation, emotional connection, and assistance in daily tasks.

**Idea 1: Entertainment Robot for Children in Waiting Rooms**  
ROSE serves as a playful companion to entertain children while their guardians attend medical appointments. It adapts games based on the number and age of participants and uses cartoon-like voices and animations to remain engaging.

**Idea 2: Retro Companion for Dementia Care**  
ROSE acts as a retro-styled companion for elderly patients with Alzheimer’s or dementia. It interacts in a 60s/70s tone, plays familiar music for memory recall, and provides basic expressions. In case of emergency, it can alert trusted contacts.

**Idea 3: Autonomous Delivery Robot in Healthcare**  
ROSE functions as an autonomous logistics assistant, capable of safely transporting items such as medication or samples between different locations. It requires safe storage, navigation tools, gripping mechanisms, and monitoring for safe handling.

## Requirements  

**Idea 1 (Children’s Robot)**  
- Visually engaging and suitable for children  
- Uses entertaining dialogues and cartoon-style speech  
- Games can be adjusted based on age and group size  

**Idea 2 (Dementia Care)**  
- Calming voice using retro speech style  
- Basic facial expressions for emotional comfort  
- Familiar regional personality tone  
- Emergency alert capability  

**Idea 3 (Logistics Robot)**  
- Safe handling of items  
- Storage and gripping capabilities  
- Ability to deliver without human help

Here os the slide with 

### Selection of Useful Design Tools
- **Cognitive Walkthrough** – for usability and interaction flow
- **Wizard of Oz** – to simulate interaction before full development
- **Bull’s-eye Diagramming / MoSCoW** – to prioritize key functions
- **Stakeholder Mapping** – to identify roles and needs of all users

### Slide
- Please find the slide with summary of our case here [View Slide](Slide.jpg)
---

## Reflections

### How is Design Research linked to HRI
Chapter 8 explains that we should design robots together with users, not just by ourselves. It says to build simple versions early then test them with people, and learn from real life. It also highlights that social robot design should be user-centered, iterative, and open-source, with real-world feedback shaping the development. 

### Digital (AI) vs Embodiment

In Chapter 9 itis clear that physical bodies are optional. Users form emotional bonds through behavior, communication, and emotional intelligence rather than mechanical embodiment.
  
### Why is HER not a compelling argument
After watching the trailer of Her movie, I understand that  emotional connection is possible without a body, confirming that behavioral and emotional presence is more important than physical form.

### The Robot Revolution: When?
-  From the given textbook, Vincent predicted that we would bond with smart devices and Bar-Cohen thought we would live with humanoid robots. In real life, Vincent predictions are currently in action as we got smart phones and voice assistants. But in near future the world is advancing to live with humanoid robots.

### Reflection: The Dinosaur Hotel
The robot hotel tried to replace all staff with robots, but they often failed when guests needed help. CitizenM used robots smartly and kept people around for real support.

### Reflection: Nabaztag
Nabaztag was a cute robot that could move and talk a little. But it lacked deep emotional interaction and adaptability, so users lost interest quickly.

### Reflection: CuddleBits
CuddleBits taught that small movements like soft shaking triggered strong emotional responses and can make people feel connected. Simple, kind behavior matters more than looking fancy and complex design.

### Reflection: Be-Right-Back
I haven't watched 'Be Right Back' (Black Mirror) but after reading about it, its evident that robots can help people but cannot fully replace real humans.

...
## Week 2 Storytelling
## Group Work 
### Story-Building Tool: *The Robot Enactment Game*

Our **story-building tool** is a **scenario-based card game** that supports storytelling in human-robot interaction. It’s designed around **Freytag’s Pyramid** and helps simulate emotionally rich social robot scenarios through role-playing and improvisation.

#### How the Game Works

**Setup:**
- One player is chosen as the **robot**.
- Other players receive an **Actor Card**.
- All players get a **Trait Card**.

> *Example Cards Below*  
> ![Trait Card](TraitCard.png)  
> ![Actor Card](ActorCard.png)

---

**The Incident:**
- A player draws an **Incident Card** and reads it aloud.
- Set a 1-minute timer.
- All participants act out their roles and react to the scenario.

> *Example Incident Card:*  
> ![Incident Card](IncidentCard.png)

---

**The Resolution:**
- Each player draws:  
  - 2 **Object Cards**,  
  - 2 **Action Cards**,  
  - and 1 **Wild Card**.
- Set the timer again.
- Players resolve the scenario **in character**, using one or more of their cards.
- Wild Cards can represent any custom solution imagined by the player.

> *Summary of Rules:*  
> ![Rules1](Rules2.png)

---

**Next Round:**
- The robot role rotates to the next player.
- Wild Cards are kept.
- Other cards are shuffled.
- New round begins with the Setup.

Full card set and template:  
[🃏 Canva Design Link](https://www.canva.com/design/DAGmrcvpGLM/G1klm_CggOCkY95wnVHsEA/edit)



---

#### Application to ROSE Robot

We adapted the game for healthcare design with ROSE robot. Two example scenarios used:

1. **Sleepless Night Scenario**  
   A child’s mother cannot sleep and screams at night—possibly due to a health crisis involving her grandmother.

2. **Bathroom Scenario**  
   An elderly man needs to use the bathroom but can’t get up from bed alone.

These scenarios helped test how a robot like ROSE could mediate distress, prioritize emergencies, or act empathetically.

---

> 💡 *Tip: Before playing, customize your cards to match the robot or context (e.g., hospital, classroom). This makes the enactment richer and more relevant.*


## Reflections

### Robot and AI Story Categories
Robot stories usually fall into a few types. Some show robots as friendly helpers (like in Wall-E), while others show them as dangerous or taking over (like Terminator). Some robots have emotions and form relationships (Her), while others are just tools or machines. There are also stories that make us think about the future and how robots may change our lives.

### Science Fiction Prototyping vs Scenario-Based Design
Science Fiction Prototyping is about creating stories based on real science to imagine future problems or changes. It focuses on what might happen and how it could affect people. Regular Scenario-Based Design is more practical. It helps designers think about how people would use a product in real life today. So, one is more about exploring ideas, and the other is about making real things work.

### Reflection: 21st Century Robot
The project wanted the robot to be friendly and easy to accept, so it became something like NAO—small, cute, and simple. But it could have been more unique. For example, the robot could have had different styles, learned from users over time, or had a different personality for different cultures. The story could have made it more interesting.

### Reflection: Product Stories vs Reality
Companies often tell exciting stories—like the robot being smart, friendly, and very helpful. But in real life, these robots can only do a few things. They are often not as good as shown in ads. The stories are made to sell the robot, not to show what it really does.

### Why Storytelling Matters in Social Robot Design
A good story helps people understand the robot and trust it. If the robot looks friendly but acts cold, people get confused. The story also helps designers explain their idea to others. So, the story needs to match how the robot looks, sounds, and behaves.

### Reflection: Healthcare vs Social Robot Stories
In healthcare, people want proof that something works before they use it. But robot designers often start with a cool idea or dream and test it later. This makes it hard for robots to be used in hospitals. Robot stories should include some real proof if they want to be taken seriously in healthcare.

## Week 3 Expression
## Group Work: Experiment and Design Tool


In our group work for **Session 3: Expression**, we explored a tool for **expressive behavior design** in social robots using both physical and digital methods. The **paper robot** experiment was aimed at simulating and puppeteering nonverbal expressions such as happiness, sadness, and listening. This helped us understand how robots can convey emotions through physical embodiment without relying on facial expressions.

#### Experiment: Paper Robot Embodiment

We started with a simple paper-based robot embodiment. The robot was created by folding a paper cube with a polystyrene ball (head) attached to it by a spring.

![Paper Robot Neutral State](PaperRobot.jpg)  
*Neutral state: Robot is calm and attentive.*

**Emotions simulated:**
1. **Neutral:** The robot maintains a stable position, neither showing extreme emotion nor reaction.
2. **Happy:** The robot's head wiggles as if expressing excitement.
3. **Sad:** The head bows down to signify sadness.
4. **Listening:** The robot's head tilts upwards toward the speaker to show attention.

**Videos of these states:**
- [Neutral State](https://photos.app.goo.gl/y7njuL2U7Rp3F9j18)
- [Happy State](https://photos.app.goo.gl/2fbrpPvGrXz1HEPD7)
- [Listening State](https://photos.app.goo.gl/BhKkMQpAKL8Hex1S6)
- [Sad State](https://photos.app.goo.gl/yo1JCWAfzobr66iE8)

#### Observations from the Experiment

After experimenting with the paper robot, we discussed the following insights:
- The **Sad state** was universally understood through the downward bow of the head.
- The **Happy state** was interpreted as excitement by some, though others felt it conveyed joy.
- The **Listening state** required clarification, as some thought the robot was asking “yes/no” rather than showing attention by tilting its head.
- This exercise helped us realize how **nonverbal communication** can express a range of emotions, even with minimal design.

---

#### **Design Tool: The Expression Game**

The **Expression Game** is designed to explore how robots can express emotions through movement, gestures, and sounds. This game allows participants to simulate a variety of robot behaviors and responses, using a set of predefined emotions. It tests the ability of a robot to convey its emotional state and how others interpret that expression. The tool aims to enhance the design of robots that can express emotions in a meaningful way.

---

#### **Rules of the Game:**

**Setup:**
- One player is chosen to be the **Robot Controller**.
- The other players are the **Guessers**.
- The **Robot Controller** draws an **Emotion Card** from a predefined list. The emotion must remain secret throughout the round.
- Players take turns being the **Robot Controller**.

**The Expression Round:**
- The **Robot Controller** has **30 seconds** to express the emotion using the available robot features (e.g., motion, lights, gestures, sounds). The robot can move and interact with the environment during this round to express the emotion.

**The Guessing:**
- After the **Expression Round**, all players (**Guessers**) cast a vote on which emotion they think the robot has expressed. Voting is done by raising hands or using other simple methods.

**The Reveal & Discussion:**
- The **Robot Controller** reveals the actual emotion.
- A short **group discussion** follows, where participants reflect on:
  - **What cues led to the guesses?**
  - **What made the expression clear or confusing?**
  - **How could the robot’s expressiveness be improved?**

**Next Round:**
- The next player clockwise becomes the new **Robot Controller**.
- A new **Emotion Card** is drawn, and the game repeats.

---
> *Summary of Rules:*  
> ![Rules2](Rules2.png)
---
#### **Experience with the Dash Robot**

In our group, we used the **Dash Robot** for this activity. Dash is a small, programmable educational robot with three degrees of freedom: two wheels for movement and a head that can pan and tilt. It also features LEDs and speakers to produce various emotional cues like lights and sounds.

![Dash](Dash.jpg)

**Steps we followed:**
1. **Familiarization with the Dash Robot**:  
   Participants first familiarized themselves with the robot's controls via a smartphone app. The robot’s capabilities, including movement, sound, and LED control, were explored.

  ![Dash Control](Dash_Control.jpg) 

3. **Emotion Selection**:  
   The **Robot Controller** selected an emotion from the predefined list (e.g., Happy, Sad, Angry, Confused). The emotion was kept secret from the other players.

4. **Expression Performance**:  
   The **Robot Controller** used the Dash Robot’s features to express the chosen emotion. This was done through:
   - **Movement**: The robot might move in a particular way to convey the emotion (e.g., slow, deliberate movements for sadness or rapid movement for excitement).
   - **Sound**: The robot might play specific sounds that align with the emotion (e.g., upbeat music for happiness or a low-pitched sound for sadness).
   - **Lights**: Dash's LED lights were used to reinforce the emotional state (e.g., red for anger, green for calmness).

5. **Guessing**:  
   After the robot’s expression, the other participants guessed the emotion based on the robot’s movements, sounds, and lights.

6. **Reveal & Discussion**:  
   The **Robot Controller** revealed the actual emotion, and the group discussed:
   - **What clues led them to their guess?**
   - **Was the robot's expression clear or ambiguous?**
   - **How could the robot's expressiveness be improved for better understanding?**

---

#### **Linking Expression and Storytelling**

This tool is also connected to our **Story-Building Game** from Session 2. By combining these tools, we could envision how the robot could react to specific scenarios with the same expressive behaviors used in our **robot enactment game**. The robot can participate in emotional storytelling, which helps us design robots that can engage in nuanced, emotionally intelligent ways.

---

#### Videos
  - [Round 1 - Confused](https://photos.app.goo.gl/mKKXT75fJZSimFBq9)
  - [Round 2 - Excited](https://photos.app.goo.gl/5Td6v3C9Th9fM2ZSA)

---
> 💡 *Note: The list of emotions is defined before the experiment by choosing at least two emotions for each of the six main groups in the Expression Wheel.*

![Expression_Wheel](Expression_Wheel.png)

### Conclusion

Using both physical and digital tools helped us reflect on the importance of **nonverbal communication** in social robots. These exercises will contribute to improving the expressiveness of robots like **ROSE**, enabling them to better interact with humans in various social settings.





### Reflections

#### **Lessons from Ju and Hoffmann**
Ju & Hoffmann's work on robot motion highlights that motion conveys meaning and can be used for expressing emotions and intentions. Applying this to my design, I can use motion to express emotional states, not just complete tasks. For instance, a robot approaching slowly could signal friendliness or caution, while quick movements may convey urgency.

#### **Laban Framework and Alternatives**
The Laban Framework is useful for describing robot motion as it relates to weight, speed, and flow. It is widely applied in HRI to design expressive robot movements. However, alternative methods such as Goffman’s Interaction Ritual Theory and the Feldenkrais Method offer different views on how motion conveys meaning. These alternatives are useful in diversifying the robot’s interaction beyond the Laban framework.

#### **Designing Robot Movement**
To design intentional movement without copying human actions, I would focus on **animacy** and **agency**. Using symbolic motion (such as stopping or tilting the head) can convey intentions without being overly anthropomorphic. For instance, a robot could communicate attention by pausing or moving in a deliberate arc rather than imitating human gestures like waving.

#### **Sound Design, Haptics and Morphology**
The Laban Framework can also inspire sound and haptic design. For example, a robot’s movement could be paired with specific sounds—quick sounds for fast motion and deep tones for slow movements. Similarly, haptic feedback like gentle vibrations can convey warmth or attention, reinforcing the robot's intention without relying on facial expressions or gestures alone.

#### **Anti-Social Robot Design**
If designing a deliberately anti-social robot, I would focus on minimal interaction, no emotional expression, and slow, stiff movement. The robot would avoid non-verbal cues like eye contact or expressive gestures, using only the most basic motions needed for functionality. This would create a robot that is functional but distant, avoiding unnecessary social engagement or emotional expression.

## Week 4 Embodiment
## Group Work

In this session, we explored embodiment as a critical element in social robot design—how a robot’s form, posture, color, and attachments shape user expectations and interpretations. Our group created a new design tool inspired by **Gartic Phone**, modified to focus on **scenario-based embodiment design**. The tool builds upon our Session 2 Story-Building Game, using the same scenario cards to prompt creative robot designs.

---

## 🎯 Design Tool: The Embodiment Game

The **Embodiment Game** is a fast-paced, drawing-based activity aimed at generating diverse robot embodiments for different social contexts. 

The tool helps participants reflect on:
- How **form defines function**
- How robot **morphology** can hint at roles or intentions
- How interpretation **shifts across iterations**

---

## 🕹️ Rules of the Game

> ![Rules Summary](./Rules3.png)

---

### 🛠️ Setup

- Each participant gets an **empty drawing card** (paper or tablet).
- One participant secretly draws a **scenario prompt** from the Story Building Card Deck.
- The scenario is **not shared** with the group.

---

### ✏️ Round 1: Drawing the Robot

- The first participant draws a **robot embodiment** suited to the secret scenario.
- Drawing can be manual or AI-generated (e.g., DALL·E, Midjourney).
- Emphasize design features such as:
  - Tools, posture, size, shape
  - Color, expressions, attachments
- ⏱️ Time limit: 2 minutes

---

### 🤔 Round 2: Guess the Scenario

- The drawing is passed clockwise to the next player.
- This participant **guesses the original scenario** based solely on the drawing.
- ❌ No clarifications or explanations are allowed.

---

### ✏️ Round 3: New Robot Design

- The guessed scenario is passed again to another participant.
- That player draws a **new robot embodiment** based on the guessed scenario.
- ⏱️ Time limit: 2 minutes
- This round **tests how ideas mutate** through visual interpretation.

---

### 💬 Discussion

Once all rounds are completed, all drawings and guesses are placed in order. Then, each player reflects on:

- **What they drew or guessed**
- **Why they made specific design choices** (e.g., tools, lights, shape)
- **What helped or confused** the interpretation

---

## 📌 Conclusion

This tool revealed how tightly **robot embodiment is linked to user perception** and how misinterpretations often arise from ambiguous design cues.

### Key Takeaways:

- Embodiments must **balance form and function**
- Small changes (posture, color, attachments) can **drastically shift** meaning
- The tool promotes **creative iteration** and **speculative thinking**


---
### Reflections

#### **Embodied vs Virtual Interaction**
- Commercial robots like **Moxie** show that physical embodiment plays a key role in how robots communicate and connect. In **Moxie’s** case, physical interaction like head movement or proximity—makes it more engaging and human-like, whereas a virtual embodiment would lack the immediacy and real-time engagement possible with physical interaction.

#### **Designing Robot Interaction**
- The paper emphasizes **embodied interaction** using human body-oriented modalities for communication. Designing robots should consider how physical presence impacts user interactions. This is crucial when deciding whether the robot should be physical (with human-like motions and gestures) or virtual (like avatars or voice-only).

#### **Anthropomorphism vs Function**
- Designing robots with **human-like traits** can be beneficial for making them approachable, but function must drive form. For example, a robot vacuum doesn’t need to resemble a human to be effective, but a companion robot might need human-like expressions to foster emotional connection. **Anthropomorphism** should not be overdone, especially if it leads to mismatched user expectations.

#### **Function Defines Form**
- The embodiment of a robot should be primarily determined by its functions. For example, a robot that must move and manipulate objects will need a design with appropriate mobility and grasping capabilities. Function-first design ensures that robots are built for practical use, with social or emotional aspects added thoughtfully for engagement.


## Week 5 Tools for ROSE
## Expression
![ROSE Expression](ROSE_Expression_1.jpg)
![ROSE Expression](ROSE_Expression_2.jpg)
![ROSE Expression](ROSE_Expression_3.jpg)


## Week 6: Behavior Group Work
## Group Work
In **Session 6: Behaviour**, we explored how to prototype high-level robot behaviour using natural language AIs like ChatGPT. Our goal was to play the **Robot Enactment Game** (from Week 2) with a **digital robot player** a GPT-powered AI.

This design tool helps us understand how to **structure interactions**, **assign intent**, and refine **robotic responses** in emotionally rich scenarios.

---

## 🎯 Design Tool: AI Extension – Behaviour

The **AI Extension** lets you use an **AI program** (e.g., ChatGPT or Character.ai) as the **robot player** in the Robot Enactment Game. It turns the storytelling experience into a **real-time behaviour simulation** challenge.

---

## 📜 Rules of the Game

> ![Rules – AI Extension](./Rules4.png)

---

### 🛠️ Setup

- Choose an AI platform like ChatGPT or Poe.
- Load or link to the **Robot Enactment Game** rules and scenario cards.
- Assign the **AI as the Robot**.
- Human players draw **Actor Cards** and **Trait Cards** as usual.

🔗 To play directly with our custom GPT called **REG ROBOT**, scan the QR or use the link below:

> ![REG Robot – Extra Link](./Link.png)  
> [https://bit.ly/robot-enactment-game](https://bit.ly/robot-enactment-game)

---

### 🎮 Playing the Game

- Begin the game as normal:
  - One player draws an **Incident Card** and reads it aloud.
  - Players act out their characters based on Actor and Trait Cards.
  - The **AI robot** must respond in character.

- During the **Resolution Phase**, the AI must:
  - Understand social and emotional dynamics
  - Prioritize conflicting needs
  - Make safe, empathetic decisions

---

### ⚠️ Challenge Mode

- You may find that the AI:
  - Gets confused about who is speaking
  - Responds too generically or passively
  - Breaks character or repeats phrases

💡 Your job is to **rephrase**, **guide**, and **prompt** the AI to perform better.

---
## 💬 Reflections

This extension teaches us:

- **How to prompt and guide an AI agent**
- That good behaviour is often the result of **clear framing**
- That **designing interactions** is about the human-AI feedback loop

Using AI like this blurs the line between **scriptwriting** and **interface design**, helping us test **how robots might act in dynamic social environments**.

---
